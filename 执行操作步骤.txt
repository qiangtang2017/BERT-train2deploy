写在前面：这个程序及博客很精彩，但是要注意版本问题，我一开始用Flask 2.0未通过，各种报错
已跑通版本：
Flask                1.0
Flask-Compress       1.11
Flask-Cors           3.0.10
Flask-JSON           0.3.4
Werkzeug             2.0.3
主要注意上面
bert-base            0.0.7
bert-serving-client  1.10.0
bert-serving-server  1.10.0


预备工作：
1、下载中文bert预训练模型，到处都是，不再介绍，bert目录与BERT-train2deploy同级别，所以引用bert模型时，用到../表示上上级目录；

2、创建output目录

3、执行以下命令：
python run_mobile.py --task_name=setiment --do_train=true --do_eval=true --data_dir=./dat  --vocab_file=../bert/chinese_L-12_H-768_A-12/vocab.txt --bert_config_file=../bert/chinese_L-12_H-768_A-12/bert_config.json --init_checkpoint=../bert/chinese_L-12_H-768_A-12/bert_model.ckpt --max_seq_length=128 --train_batch_size=32 --learning_rate=2e-5 --num_train_epochs=5.0 --output_dir=./output

4、训练结束后，在output目录下看训练完的模型
5、预测
python run_mobile.py --task_name=setiment --do_predict=true --data_dir=./dat  --vocab_file=../bert/chinese_L-12_H-768_A-12/vocab.txt --bert_config_file=../bert/chinese_L-12_H-768_A-12/bert_config.json --init_checkpoint=../bert/chinese_L-12_H-768_A-12/bert_model.ckpt --max_seq_length=128 --output_dir=./output

6、转化pb格式
python freeze_graph.py -bert_model_dir ../bert/chinese_L-12_H-768_A-12 -model_dir output -max_seq_len 128 -num_labels 3
 
7、开启服务
bert-base-serving-start -model_dir ./output -bert_model_dir ../bert/chinese_L-12_H-768_A-12 -model_pb_dir ./output -mode CLASS -max_seq_len 128 -http_port 8091 -port 5575 -port_out 5576  

8、测试是否可以通
curl -X POST http://10.0.0.67:8091/encode -H 'content-type: application/json' -d '{"id": 111,"texts": ["总的来说，这款手机性价比是特别高的。","槽糕的售后服务！！！店大欺客"], "is_tokenized": false}'
